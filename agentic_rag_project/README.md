
# Agentic RAG Project

A modern Agentic RAG (Retrieval-Augmented Generation) system built with Pydantic AI, FastAPI, and PostgreSQL (pgvector). This project provides a scalable, modular, and production-ready foundation for document-based AI applications.
## ğŸ“‹ Table of Contents

- [Features](#features)
- [Tech Stack](#tech-stack)
- [Installation](#installation)
- [Usage](#usage)
- [API Reference](#api-reference)
- [Project Structure](#project-structure)
- [Development](#development)
- [Testing](#testing)
- [License](#license)

## âœ¨ Features

- ğŸ§  Pydantic AI-based intelligent agent system
- ğŸ” Multiple search strategies: Vector Search and Hybrid Search
- ğŸ“„ Advanced PDF processing: Table and image extraction with Docling
- ğŸ’¾ Database: PostgreSQL + pgvector extension
- ğŸŒŠ Real-time streaming: Live responses via Server-Sent Events
- ğŸ¯ Session management: Conversation history and context retention
- ğŸ³ Docker containerization: Easy deployment
- ğŸ”§ Type safety: Reliable data handling with Pydantic models
- âš¡ Instant ingestion: Upload documents and query immediately

## ğŸ› ï¸ Tech Stack

### Backend

- [Pydantic AI](https://ai.pydantic.dev/) - AI Agent Framework
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [LangChain](https://langchain.readthedocs.io/) - Document processing and embeddings
- [Docling](https://github.com/DS4SD/docling) - PDF extraction and analysis
- [AsyncPG](https://magicstack.github.io/asyncpg/) - PostgreSQL async client
- [pgvector](https://github.com/pgvector/pgvector) - Vector similarity search

### Frontend

- [Streamlit](https://streamlit.io/) - Interactive web interface

### Infrastructure

- [PostgreSQL 17](https://www.postgresql.org/) - Primary database
- [Docker Compose](https://docs.docker.com/compose/) - Multi-container deployment
- [uv](https://github.com/astral-sh/uv) - Fast Python package installer

## ğŸš€ Installation

### Prerequisites

- Python 3.12+
- Docker & Docker Compose
- Git

### 1. Clone the Repository

```bash
git clone https://github.com/serkanyasr/ntt_rag_project.git
cd ntt_rag_project
```

### 2. Set Up Environment Variables

Create a `.env` file:

```bash
# API Configuration
APP_ENV=development
LOG_LEVEL=INFO
APP_HOST=0.0.0.0
APP_PORT=8058
API_URL=http://api:8058

# Streamlit Configuration
SERVER_PORT=8501
SERVER_HOST=0.0.0.0

# PostgreSQL Vector DB Configuration
DB_USER=postgres
DB_PASSWORD=postgres
DB_HOST=postgres
DB_PORT=5432
DB_NAME=vector_db

# OpenAI API Configuration (required)
OPENAI_API_KEY=your_openai_api_key
LLM_CHOICE=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small
```

### 3. Start with Docker

```bash
docker-compose up -d
docker-compose logs -f
```

## ğŸ“š Usage

### Web Interface

Access the Streamlit UI: <http://localhost:8501>

The web interface now includes:

- **Interactive Chat**: Ask questions about your uploaded documents
- **Health Monitoring**: Check API connection status
- **Session Management**: Persistent conversation history

### API Usage

FastAPI documentation: <http://localhost:8058/docs>

#### Chat Endpoint Example

```python
import requests

response = requests.post("http://localhost:8058/chat", json={
    "message": "Hello, how can I help you?",
    "session_id": "optional-session-id",
    "user_id": "user-123",
    "search_type": "hybrid"
})
print(response.json())
```

#### Streaming Chat Example

```python
import requests
import json

response = requests.post(
    "http://localhost:8058/chat/stream",
    json={
        "message": "Give a long explanation",
        "search_type": "hybrid"
    },
    stream=True
)

for line in response.iter_lines():
    if line.startswith(b'data: '):
        data = json.loads(line[6:])
        if data.get("type") == "text":
            print(data.get("content"), end="")
```

### Document Ingestion

#### Command Line Ingestion

```bash
# Place your PDF documents in the documents/ folder
cp your_document.pdf documents/

# Run the ingestion script
python -m ingestion.ingest --documents documents/
```

## ğŸ“– API Reference

### Endpoints

#### Chat Endpoints

- `POST /chat` - Single chat message
- `POST /chat/stream` - Streaming chat
- `GET /chat/sessions/{session_id}` - Session history

#### Search Endpoints

- `POST /search/vector` - Vector search
- `POST /search/hybrid` - Hybrid search

#### Health Check

- `GET /health` - System status

### Request/Response Models

#### Chat Request

```json
{
  "message": "Your question",
  "session_id": "optional-session-id",
  "user_id": "user-id",
  "search_type": "hybrid",
  "metadata": {}
}
```


#### Search Request

```json
{
  "query": "Search query",
  "search_type": "vector",
  "limit": 10,
  "filters": {}
}
```

## ğŸ—ï¸ Project Structure

```text
ntt_rag_project/
â”œâ”€â”€ agent/                  # AI Agent and business logic
â”‚   â”œâ”€â”€ agent.py           # Main Pydantic AI agent
â”‚   â”œâ”€â”€ api.py             # FastAPI endpoints
â”‚   â”œâ”€â”€ db_utils.py        # Database operations
â”‚   â”œâ”€â”€ models.py          # Pydantic models
â”‚   â”œâ”€â”€ prompts.py         # System prompts
â”‚   â”œâ”€â”€ providers.py       # LLM and embedding providers
â”‚   â””â”€â”€ tools.py           # Agent tools
â”œâ”€â”€ ingestion/             # Document processing
â”‚   â”œâ”€â”€ chunker.py         # Text chunking
â”‚   â”œâ”€â”€ extract_files.py   # PDF extraction
â”‚   â””â”€â”€ ingest.py          # Main ingestion pipeline
â”œâ”€â”€ ui/                    # Streamlit UI
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ sql/                   # Database schema
â”‚   â””â”€â”€ schema.sql
â”œâ”€â”€ tests/                 # Test files
â”œâ”€â”€ documents/             # PDF documents
â”œâ”€â”€ docker-compose.yml     # Container orchestration
â”œâ”€â”€ Dockerfile
â””â”€â”€ pyproject.toml         # Python dependencies
```

### Main Components

#### Agent (`/agent/`)

- **agent.py**: Pydantic AI agent definition and tool registrations
- **api.py**: FastAPI web server and endpoints
- **tools.py**: Vector search, hybrid search, document retrieval tools
- **db_utils.py**: PostgreSQL operations and connection management
- **models.py**: Pydantic data models and validation

#### Ingestion (`/ingestion/`)

- **ingest.py**: Main document processing pipeline
- **extract_files.py**: PDF text, table, and image extraction
- **chunker.py**: Intelligent text chunking strategies

## ğŸ§ª Testing

### Running Tests

```bash
pytest
pytest tests/agent/test_models.py
pytest --cov=agent --cov=ingestion
```

### Test Categories

- **Model Tests**: Pydantic model validation
- **Agent Tests**: AI agent functionality
- **Database Tests**: PostgreSQL operations
- **Ingestion Tests**: Document processing

## âš™ï¸ Development

### Development Setup

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install uv
uv pip install -r pyproject.toml
pre-commit install
```


### Logging

```bash
export LOG_LEVEL=DEBUG
docker-compose logs -f api
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `DB_NAME` | PostgreSQL database name | `rag_db` |
| `DB_USER` | PostgreSQL user | `rag_user` |
| `DB_PASSWORD` | PostgreSQL password | - |
| `OPENAI_API_KEY` | OpenAI API key | - |
| `APP_PORT` | FastAPI port | `8058` |
| `SERVER_PORT` | Streamlit port | `8501` |
| `LLM_MODEL` | LLM model | `gpt-4` |
| `EMBEDDING_MODEL` | Embedding model | `text-embedding-3-small` |

### Docker Compose Overrides

You can create a `docker-compose.override.yml` for custom configurations.

## ğŸ› Troubleshooting

### Common Issues

#### Database Connection Error

```bash
docker-compose ps postgres
docker-compose logs postgres
```

#### OpenAI API Error

```bash
echo $OPENAI_API_KEY
```

#### Port Conflicts

```bash
netstat -an | grep :8058
netstat -an | grep :8501
```

## ğŸ“„ License

MIT License - See `LICENSE` for details.

---
